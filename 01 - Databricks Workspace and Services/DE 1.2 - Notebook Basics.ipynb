{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "489022de-29e0-4df7-9f34-fce53c6fa088",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44e0b830-2052-449a-9173-a9cbcedc1be3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"48031791-53af-4737-8c15-280e45fb9226\"/>\n",
    "\n",
    "\n",
    "# Notebook Basics\n",
    "\n",
    "Notebooks are the primary means of developing and executing code interactively on Databricks. This lesson provides a basic introduction to working with Databricks notebooks.\n",
    "\n",
    "If you've previously used Databricks notebooks but this is your first time executing a notebook in Databricks Repos, you'll notice that basic functionality is the same. In the next lesson, we'll review some of the functionality that Databricks Repos adds to notebooks.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson, you should be able to:\n",
    "* Attach a notebook to a cluster\n",
    "* Execute a cell in a notebook\n",
    "* Set the language for a notebook\n",
    "* Describe and use magic commands\n",
    "* Create and run a SQL cell\n",
    "* Create and run a Python cell\n",
    "* Create a markdown cell\n",
    "* Export a Databricks notebook\n",
    "* Export a collection of Databricks notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a20e65ef-d68b-4d81-92f8-c7d7b9dc3947",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"96041d75-d411-45db-8add-986022e62159\"/>\n",
    "\n",
    "\n",
    "## Attach to a Cluster\n",
    "\n",
    "In the previous lesson, you should have either deployed a cluster or identified a cluster that an admin has configured for you to use.\n",
    "\n",
    "Directly below the name of this notebook at the top of your screen, use the drop-down list to connect this notebook to your cluster.\n",
    "\n",
    "**NOTE**: Deploying a cluster can take several minutes. A green arrow will appear to the right of the cluster name once resources have been deployed. If your cluster has a solid gray circle to the left, you will need to follow instructions to <a href=\"https://docs.databricks.com/clusters/clusters-manage.html#start-a-cluster\" target=\"_blank\">start a cluster</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "febaa6cf-7c4b-4d44-af35-6e060654c662",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"9f021e76-692f-4df7-8e80-fec41d03c719\"/>\n",
    "\n",
    "\n",
    "## Notebooks Basics\n",
    "\n",
    "Notebooks provide cell-by-cell execution of code. Multiple languages can be mixed in a notebook. Users can add plots, images, and markdown text to enhance their code.\n",
    "\n",
    "Throughout this course, our notebooks are designed as learning instruments. Notebooks can be easily deployed as production code with Databricks, as well as providing a robust toolset for data exploration, reporting, and dashboarding.\n",
    "\n",
    "### Running a Cell\n",
    "* Run the cell below using one of the following options:\n",
    "  * **CTRL+ENTER** or **CTRL+RETURN**\n",
    "  * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one\n",
    "  * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style=\"box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);\" src=\"https://files.training.databricks.com/images/notebook-cell-run-cmd.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4012bc65-1318-47c4-8ea6-691fa24fd338",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm running Python!\n"
     ]
    }
   ],
   "source": [
    "print(\"I'm running Python!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ea083a7-0fdd-4418-bb8d-7dc35a30c547",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"cea571b2-8a27-495f-a1ee-7e270d688d62\"/>\n",
    "\n",
    "\n",
    "**NOTE**: Cell-by-cell code execution means that cells can be executed multiple times or out of order. Unless explicitly instructed, you should always assume that the notebooks in this course are intended to be run one cell at a time from top to bottom. If you encounter an error, make sure you read the text before and after a cell to ensure that the error wasn't an intentional learning moment before you try to troubleshoot. Most errors can be resolved by either running earlier cells in a notebook that were missed or re-executing the entire notebook from the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "392ca5b8-e524-469e-b1bb-827c80026851",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"702cb769-7d37-4b1a-8131-292f37d4c8e6\"/>\n",
    "\n",
    "\n",
    "### Setting the Default Notebook Language\n",
    "\n",
    "The cell above executes a Python command, because our current default language for the notebook is set to Python.\n",
    "\n",
    "Databricks notebooks support Python, SQL, Scala, and R. A language can be selected when a notebook is created, but this can be changed at any time.\n",
    "\n",
    "The default language appears directly to the right of the notebook title at the top of the page. Throughout this course, we'll use a blend of SQL and Python notebooks.\n",
    "\n",
    "We'll change the default language for this notebook to SQL.\n",
    "\n",
    "Steps:\n",
    "* Click on the **Python** next to the notebook title at the top of the screen\n",
    "* In the UI that pops up, select **SQL** from the drop down list \n",
    "\n",
    "**NOTE**: In the cell just before this one, you should see a new line appear with <strong><code>&#37;python</code></strong>. We'll discuss this in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4467c8ac-32e7-463f-96f8-d0317c13559e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"0e12c7f2-4169-40d6-b065-5b6e1454ae2a\"/>\n",
    "\n",
    "\n",
    "### Create and Run a SQL Cell\n",
    "\n",
    "* Highlight this cell and press the **B** button on the keyboard to create a new cell below\n",
    "* Copy the following code into the cell below and then run the cell\n",
    "\n",
    "**`%sql`**<br/>\n",
    "**`SELECT \"I'm running SQL!\"`**\n",
    "\n",
    "**NOTE**: There are a number of different methods for adding, moving, and deleting cells including GUI options and keyboard shortcuts. Refer to the <a href=\"https://docs.databricks.com/notebooks/notebooks-use.html#develop-notebooks\" target=\"_blank\">docs</a> for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b5f19a9-de5c-41b9-811a-9bfa8173b10b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"828d14d2-a661-45e4-a555-0b86896c31d4\"/>\n",
    "\n",
    "\n",
    "## Magic Commands\n",
    "* Magic commands are specific to the Databricks notebooks\n",
    "* They are very similar to magic commands found in comparable notebook products\n",
    "* These are built-in commands that provide the same outcome regardless of the notebook's language\n",
    "* A single percent (%) symbol at the start of a cell identifies a magic command\n",
    "  * You can only have one magic command per cell\n",
    "  * A magic command must be the first thing in a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cae483c-4396-4254-9bcb-da28ef7d00bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"19380cb5-20d3-4bd6-abd6-ae09082f2451\"/>\n",
    "\n",
    "\n",
    "### Language Magics\n",
    "Language magic commands allow for the execution of code in languages other than the notebook's default. In this course, we'll see the following language magics:\n",
    "* <strong><code>&#37;python</code></strong>\n",
    "* <strong><code>&#37;sql</code></strong>\n",
    "\n",
    "Adding the language magic for the currently set notebook type is not necessary.\n",
    "\n",
    "When we changed the notebook language from Python to SQL above, existing cells written in Python had the <strong><code>&#37;python</code></strong> command added.\n",
    "\n",
    "**NOTE**: Rather than changing the default language of a notebook constantly, you should stick with a primary language as the default and only use language magics as necessary to execute code in another language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f704b9c3-aec2-430c-a8a2-5c547cc3ae2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Python!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello Python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0583f5c9-dde2-4fe4-acea-5fa2ab4ae544",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Hello SQL!</th></tr></thead><tbody><tr><td>Hello SQL!</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Hello SQL!"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Hello SQL!",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "select \"Hello SQL!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdcad842-17db-438e-8dac-fb9f029bd3a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"81f29d75-0c8f-47d3-a052-7664f3e2bc83\"/>\n",
    "\n",
    "\n",
    "\n",
    "### Markdown\n",
    "\n",
    "The magic command **&percnt;md** allows us to render Markdown in a cell:\n",
    "* Double click this cell to begin editing it\n",
    "* Then hit **`Esc`** to stop editing\n",
    "\n",
    "# Title One\n",
    "## Title Two\n",
    "### Title Three\n",
    "\n",
    "This is a test of the emergency broadcast system. This is only a test.\n",
    "\n",
    "This is text with a **bold** word in it.\n",
    "\n",
    "This is text with an *italicized* word in it.\n",
    "\n",
    "This is an ordered list\n",
    "1. once\n",
    "1. two\n",
    "1. three\n",
    "\n",
    "This is an unordered list\n",
    "* apples\n",
    "* peaches\n",
    "* bananas\n",
    "\n",
    "Links/Embedded HTML: <a href=\"https://en.wikipedia.org/wiki/Markdown\" target=\"_blank\">Markdown - Wikipedia</a>\n",
    "\n",
    "Images:\n",
    "![Spark Engines](https://files.training.databricks.com/images/Apache-Spark-Logo_TM_200px.png)\n",
    "\n",
    "And of course, tables:\n",
    "\n",
    "| name   | value |\n",
    "|--------|-------|\n",
    "| Yi     | 1     |\n",
    "| Ali    | 2     |\n",
    "| Selina | 3     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db630acc-244a-4f00-9be5-fedfcdaf3641",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"8bdf271e-346f-4ec8-b49c-a7593a5f1f6c\"/>\n",
    "\n",
    "\n",
    "### %run\n",
    "* You can run a notebook from another notebook by using the magic command **%run**\n",
    "* Notebooks to be run are specified with relative paths\n",
    "* The referenced notebook executes as if it were part of the current notebook, so temporary views and other local declarations will be available from the calling notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12f98bc1-57da-48da-b085-420efdea5558",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"739cd1b9-dac7-40f7-8c33-9a3c91eec348\"/>\n",
    "\n",
    "\n",
    "Uncommenting and executing the following cell will generate the following error:<br/>\n",
    "**`Error in SQL statement: AnalysisException: Table or view not found: demo_tmp_vw`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "699943cb-1d87-4e03-901d-178889b8bc21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-2603255858052248>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m   \u001B[0m_sqldf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m<command-2603255858052248>\u001B[0m in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mimport\u001B[0m \u001B[0mbase64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"U0VMRUNUICogRlJPTSBkZW1vX3RtcF92dw==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n\u001B[1;32m   1117\u001B[0m             \u001B[0msqlQuery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1118\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1119\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1120\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1121\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    200\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAnalysisException\u001B[0m: Table or view not found: demo_tmp_vw; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [demo_tmp_vw], [], false\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-2603255858052248>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m   \u001B[0m_sqldf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m   \u001B[0;32mdel\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m<command-2603255858052248>\u001B[0m in \u001B[0;36m____databricks_percent_sql\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m____databricks_percent_sql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0;32mimport\u001B[0m \u001B[0mbase64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbase64\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandard_b64decode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"U0VMRUNUICogRlJPTSBkZW1vX3RtcF92dw==\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mdisplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/session.py\u001B[0m in \u001B[0;36msql\u001B[0;34m(self, sqlQuery, **kwargs)\u001B[0m\n\u001B[1;32m   1117\u001B[0m             \u001B[0msqlQuery\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mformatter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1118\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1119\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jsparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msqlQuery\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1120\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1121\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    200\u001B[0m                 \u001B[0;31m# Hide where the exception came from that shows a non-Pythonic\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m                 \u001B[0;31m# JVM exception message.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 202\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mconverted\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    203\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    204\u001B[0m                 \u001B[0;32mraise\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAnalysisException\u001B[0m: Table or view not found: demo_tmp_vw; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [demo_tmp_vw], [], false\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: Table or view not found: demo_tmp_vw; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [demo_tmp_vw], [], false\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM demo_tmp_vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ea054d1-c9ce-47c9-8b39-ac7908530c8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"d9e357e2-f605-4aae-be7d-9254361e2147\"/>\n",
    "\n",
    "\n",
    "But we can declare it and a handful of other variables and functions buy running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "634447ac-79d0-4d56-8935-c674670b0014",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nPython interpreter will be restarted.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| No action taken\n\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\"\n\nValidating the locally installed datasets:\n| listing local files...(8 seconds)\n| validation completed...(8 seconds total)\n\nCreating the temp view \"demo_tmp_vw\"\n\nUsing the \"default\" schema.\n\nPredefined paths variables:\n| DA.paths.working_dir: dbfs:/mnt/dbacademy-users/odl_user_917217@databrickslabs.com/data-engineering-with-databricks\n| DA.paths.user_db:     dbfs:/mnt/dbacademy-users/odl_user_917217@databrickslabs.com/data-engineering-with-databricks/database.db\n| DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02\n| DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/odl_user_917217@databrickslabs.com/data-engineering-with-databricks/_checkpoints\n\nSetup completed (17 seconds)\n"
     ]
    }
   ],
   "source": [
    "%run ../Includes/Classroom-Setup-01.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50409f9e-4099-443c-9caa-8102a4514803",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"e7a9c7ec-1d61-42d6-91c9-ece07d2aa2a3\"/>\n",
    "\n",
    "\n",
    "The **`../Includes/Classroom-Setup-01.2`** notebook we referenced includes logic to create and **`USE`** a database, as well as creating the temp view **`demo_temp_vw`**.\n",
    "\n",
    "We can see this temp view is now available in our current notebook session with the following query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19d9f39b-75cc-4546-bbeb-ab8cc5e9f65b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>value</th></tr></thead><tbody><tr><td>Yi</td><td>1</td></tr><tr><td>Ali</td><td>2</td></tr><tr><td>Selina</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Yi",
         1
        ],
        [
         "Ali",
         2
        ],
        [
         "Selina",
         3
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql \n",
    "SELECT * FROM demo_tmp_vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33597db7-7ca6-496d-8ed9-92620300e048",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"fd9afa7b-7efd-421e-9a22-61e7d6533a52\"/>\n",
    "\n",
    "\n",
    "We'll use this pattern of \"setup\" notebooks throughout the course to help configure the environment for lessons and labs.\n",
    "\n",
    "These \"provided\" variables, functions and other objects should be easily identifiable in that they are part of the **`DA`** object which is an instance of **`DBAcademyHelper`**.\n",
    "\n",
    "With that in mind, most lessons will use variables derived from your username to organize files and databases. \n",
    "\n",
    "This pattern allows us to avoid collision with other users in shared a workspace.\n",
    "\n",
    "The cell below uses Python to print some of those variables previously defined in this notebook's setup script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83df84eb-17a9-4407-b53d-f3500ab425b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DA:                   <dbacademy.dbhelper.dbacademy_helper_class.DBAcademyHelper object at 0x7f1cc865f5e0>\nDA.username:          odl_user_917217@databrickslabs.com\nDA.paths.working_dir: dbfs:/mnt/dbacademy-users/odl_user_917217@databrickslabs.com/data-engineering-with-databricks\nDA.schema_name:       odl_user_917217_t5q1_da_dewd\n"
     ]
    }
   ],
   "source": [
    "print(f\"DA:                   {DA}\")\n",
    "print(f\"DA.username:          {DA.username}\")\n",
    "print(f\"DA.paths.working_dir: {DA.paths.working_dir}\")\n",
    "print(f\"DA.schema_name:       {DA.schema_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9366500f-c436-486a-a503-b5fd08031839",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"f28a5e07-c955-460c-8779-6eb3f7306b19\"/>\n",
    "\n",
    "\n",
    "In addition to this, these same variables are \"injected\" into the SQL context so that we can use them in SQL statements.\n",
    "\n",
    "We will talk more about this later, but you can see a quick example in the following cell.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/icon_note_32.png\"> Note the subtle but important difference in the casing of the word **`da`** and **`DA`** in these two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9afb3631-78a8-40f1-bc75-a828df90b578",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>current_username</th><th>working_directory</th><th>schema_name</th></tr></thead><tbody><tr><td>odl_user_917217@databrickslabs.com</td><td>dbfs:/mnt/dbacademy-users/odl_user_917217@databrickslabs.com/data-engineering-with-databricks</td><td>odl_user_917217_t5q1_da_dewd</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "odl_user_917217@databrickslabs.com",
         "dbfs:/mnt/dbacademy-users/odl_user_917217@databrickslabs.com/data-engineering-with-databricks",
         "odl_user_917217_t5q1_da_dewd"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "current_username",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "working_directory",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "schema_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT '${da.username}' AS current_username,\n",
    "       '${da.paths.working_dir}' AS working_directory,\n",
    "       '${da.schema_name}' as schema_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a48350a-6fbd-45eb-b9cd-605cc9f352d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"cf6ff3b4-2f4b-4fed-9d56-1e5f1b4fbb83\"/>\n",
    "\n",
    "\n",
    "## Databricks Utilities\n",
    "Databricks notebooks provide a number of utility commands for configuring and interacting with the environment: <a href=\"https://docs.databricks.com/user-guide/dev-tools/dbutils.html\" target=\"_blank\">dbutils docs</a>\n",
    "\n",
    "Throughout this course, we'll occasionally use **`dbutils.fs.ls()`** to list out directories of files from Python cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68364c3d-a429-43d4-9c27-f7c5b6aa7868",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[15]: [FileInfo(path='dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/ecommerce/', name='ecommerce/', size=0, modificationTime=1681729015288),\n FileInfo(path='dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/flights/', name='flights/', size=0, modificationTime=1681729015288),\n FileInfo(path='dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/healthcare/', name='healthcare/', size=0, modificationTime=1681729015288),\n FileInfo(path='dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/nyctaxi-with-zipcodes/', name='nyctaxi-with-zipcodes/', size=0, modificationTime=1681729015288),\n FileInfo(path='dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/retail-org/', name='retail-org/', size=0, modificationTime=1681729015288),\n FileInfo(path='dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/weather/', name='weather/', size=0, modificationTime=1681729015288)]"
     ]
    }
   ],
   "source": [
    "path = f\"{DA.paths.datasets}\"\n",
    "dbutils.fs.ls(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577bb1e1-f909-435c-8ecf-82149ce39967",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b58df4d5-09b7-4a63-89d8-69363d32e37b\"/>\n",
    "\n",
    "\n",
    "## display()\n",
    "\n",
    "When running SQL queries from cells, results will always be displayed in a rendered tabular format.\n",
    "\n",
    "When we have tabular data returned by a Python cell, we can call **`display`** to get the same type of preview.\n",
    "\n",
    "Here, we'll wrap the previous list command on our file system with **`display`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3d32dfe-2524-414f-825b-2af45739ac18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/ecommerce/</td><td>ecommerce/</td><td>0</td><td>1681729021149</td></tr><tr><td>dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/flights/</td><td>flights/</td><td>0</td><td>1681729021149</td></tr><tr><td>dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/healthcare/</td><td>healthcare/</td><td>0</td><td>1681729021149</td></tr><tr><td>dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/nyctaxi-with-zipcodes/</td><td>nyctaxi-with-zipcodes/</td><td>0</td><td>1681729021149</td></tr><tr><td>dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/retail-org/</td><td>retail-org/</td><td>0</td><td>1681729021149</td></tr><tr><td>dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/weather/</td><td>weather/</td><td>0</td><td>1681729021149</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/ecommerce/",
         "ecommerce/",
         0,
         1681729021149
        ],
        [
         "dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/flights/",
         "flights/",
         0,
         1681729021149
        ],
        [
         "dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/healthcare/",
         "healthcare/",
         0,
         1681729021149
        ],
        [
         "dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/nyctaxi-with-zipcodes/",
         "nyctaxi-with-zipcodes/",
         0,
         1681729021149
        ],
        [
         "dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/retail-org/",
         "retail-org/",
         0,
         1681729021149
        ],
        [
         "dbfs:/mnt/dbacademy-datasets/data-engineering-with-databricks/v02/weather/",
         "weather/",
         0,
         1681729021149
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = f\"{DA.paths.datasets}\"\n",
    "files = dbutils.fs.ls(path)\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30822adb-37fc-4fc8-a63e-aa4db8f44ccd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"4ee5258a-3c18-47d5-823c-01596b4787c4\"/>\n",
    "\n",
    "\n",
    "The **`display()`** command has the following capabilities and limitations:\n",
    "* Preview of results limited to 1000 records\n",
    "* Provides button to download results data as CSV\n",
    "* Allows rendering plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60b99850-2409-4ff3-bf4c-b809a7b052b5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b1e79003-3240-4a4e-84e3-a7902f969631\"/>\n",
    "\n",
    "\n",
    "## Downloading Notebooks\n",
    "\n",
    "There are a number of options for downloading either individual notebooks or collections of notebooks.\n",
    "\n",
    "Here, you'll go through the process to download this notebook as well as a collection of all the notebooks in this course.\n",
    "\n",
    "### Download a Notebook\n",
    "\n",
    "Steps:\n",
    "* Click the **File** option to the right of the cluster selection at the top of the notebook\n",
    "* From the menu that appears, hover over **Export** and then select **Source File**\n",
    "\n",
    "The notebook will download to your personal laptop. It will be named with the current notebook name and have the file extension for the default language. You can open this notebook with any file editor and see the raw contents of Databricks notebooks.\n",
    "\n",
    "These source files can be uploaded into any Databricks workspace.\n",
    "\n",
    "### Download a Collection of Notebooks\n",
    "\n",
    "**NOTE**: The following instructions assume you have imported these materials using **Repos**.\n",
    "\n",
    "Steps:\n",
    "* Click the  ![](https://files.training.databricks.com/images/repos-icon.png) **Repos** on the left sidebar\n",
    "  * This should give you a preview of the parent directories for this notebook\n",
    "* On the left side of the directory preview around the middle of the screen, there should be a left arrow. Click this to move up in your file hierarchy.\n",
    "* You should see a directory called **Data Engineering with Databricks**. Click the the down arrow/chevron to bring up a menu\n",
    "* From the menu, hover over **Export** and select **DBC Archive**\n",
    "\n",
    "The DBC(Databricks Cloud) file that is downloaded contains a zipped collection of the directories and notebooks in this course. Users should not attempt to edit these DBC files locally, but they can be safely uploaded into any Databricks workspace to move or share notebook contents.\n",
    "\n",
    "**NOTE**: When downloading a collection of DBCs, result previews and plots will also be exported. When downloading source notebooks, only code will be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb84f7be-a184-4277-bdb8-3ecc45374e97",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"37f4f2b0-5f6e-45d6-9ee4-3f90348f8277\"/>\n",
    "\n",
    "\n",
    "## Learning More\n",
    "\n",
    "We like to encourage you to explore the documentation to learn more about the various features of the Databricks platform and notebooks.\n",
    "* <a href=\"https://docs.databricks.com/user-guide/index.html#user-guide\" target=\"_blank\">User Guide</a>\n",
    "* <a href=\"https://docs.databricks.com/user-guide/getting-started.html\" target=\"_blank\">Getting Started with Databricks</a>\n",
    "* <a href=\"https://docs.databricks.com/user-guide/notebooks/index.html\" target=\"_blank\">User Guide / Notebooks</a>\n",
    "* <a href=\"https://docs.databricks.com/notebooks/notebooks-manage.html#notebook-external-formats\" target=\"_blank\">Importing notebooks - Supported Formats</a>\n",
    "* <a href=\"https://docs.databricks.com/repos/index.html\" target=\"_blank\">Repos</a>\n",
    "* <a href=\"https://docs.databricks.com/administration-guide/index.html#administration-guide\" target=\"_blank\">Administration Guide</a>\n",
    "* <a href=\"https://docs.databricks.com/user-guide/clusters/index.html\" target=\"_blank\">Cluster Configuration</a>\n",
    "* <a href=\"https://docs.databricks.com/api/latest/index.html#rest-api-2-0\" target=\"_blank\">REST API</a>\n",
    "* <a href=\"https://docs.databricks.com/release-notes/index.html#release-notes\" target=\"_blank\">Release Notes</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2338e8b8-5630-4b94-b5e8-b3bba8ea2cb8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<i18n value=\"b3cc4b2f-a3ee-4602-bee8-b2b8fad2684a\"/>\n",
    "\n",
    "\n",
    "## One more note! \n",
    "\n",
    "At the end of each lesson you will see the following command, **`DA.cleanup()`**.\n",
    "\n",
    "This method drops lesson-specific databases and working directories in an attempt to keep your workspace clean and maintain the immutability of each lesson.\n",
    "\n",
    "Run the following cell to delete the tables and files associated with this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "524c30e7-acfc-4101-a720-0734e0a2fab6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting the learning environment:\n| No action taken\n\nValidating the locally installed datasets:\n| listing local files...(7 seconds)\n| validation completed...(7 seconds total)\n"
     ]
    }
   ],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74e72028-701b-4d6c-8477-c400fc17f6c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "&copy; 2023 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2603255858052261,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "DE 1.2 - Notebook Basics",
   "notebookOrigID": 2603255858052135,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
